# Grant Research Automation - Strategic Design Document

## üéØ **Executive Summary**

This document outlines the comprehensive redesign of the Grant Research Automation platform, transitioning from a Docker-based container system to a modern, maintainable Python application designed for development with VSCode and Claude Code.

### **Project Objectives**
- **Streamline Grant Discovery**: Automate the identification and analysis of potential funding opportunities
- **Enhance Research Efficiency**: Reduce manual research time from weeks to hours
- **Improve Decision Making**: Provide data-driven insights for grant strategy
- **Scale Operations**: Handle large-scale research across multiple states and sectors
- **Ensure Maintainability**: Create a codebase that's easy to extend and modify

---

## üìä **Current State Analysis**

### **Existing Assets**
- ‚úÖ **8 Core Processing Scripts**: Proven workflow components
- ‚úÖ **Data Sources**: IRS BMF, ProPublica API, 990 filings
- ‚úÖ **Basic Scoring Algorithm**: Financial and mission-based evaluation
- ‚úÖ **Manual Workflow**: Understanding of complete research process

### **Current Limitations**
- üî¥ **Docker Complexity**: Difficult to develop and debug
- üî¥ **Script Isolation**: No unified workflow management
- üî¥ **Limited Scalability**: Manual execution and monitoring
- üî¥ **No Real-time Monitoring**: Poor visibility into progress
- üî¥ **Basic Reporting**: Limited export and analysis capabilities
- üî¥ **Manual Configuration**: No user-friendly interface

### **Technical Debt Issues**
- Hardcoded file paths and configurations
- Inconsistent error handling across scripts
- No unified logging or state management
- Limited testing and validation
- Poor code reusability and modularity

---

## üöÄ **Future State Vision**

### **Primary Research Capabilities**

#### **1. Organization Profiling & Discovery**
- **Target Analysis**: Deep dive into specific organizations using EIN lookup
- **Keyword Extraction**: AI-powered mission and activity analysis
- **NTEE Matching**: Intelligent categorization and similar organization discovery
- **Financial Profiling**: Comprehensive financial health assessment

#### **2. Multi-Source Data Integration**
- **IRS Business Master File**: Complete nonprofit database filtering
- **ProPublica API**: Automated 990 filing retrieval and analysis
- **Grants.gov Integration**: Federal grant opportunity matching
- **State/Local Sources**: Regional funding opportunity identification
- **PDF/XML Processing**: Automated document analysis and data extraction

#### **3. Advanced Scoring & Ranking**
- **Composite Scoring**: Multi-factor evaluation algorithm
- **Customizable Weights**: Adjustable scoring criteria by sector
- **Historical Trends**: Multi-year performance analysis
- **Risk Assessment**: Financial stability and compliance evaluation
- **Mission Alignment**: Semantic similarity matching

#### **4. Relationship Mapping & Network Analysis**
- **Board Member Networks**: Cross-organizational relationship mapping
- **Grant Flow Analysis**: Schedule I grant patterns and connections
- **Similarity Clustering**: Find organizations with similar missions/finances
- **Geographic Mapping**: Regional impact and funding pattern analysis

### **Secondary Research & Intelligence**

#### **1. Competitive Intelligence**
- **Peer Organization Analysis**: Identify similar organizations and their funding
- **Grant Success Patterns**: Historical grant award analysis
- **Board Overlap Analysis**: Shared board members and potential connections
- **Geographic Clustering**: Regional funding ecosystem mapping

#### **2. Opportunity Identification**
- **New Funder Discovery**: Identify emerging grant makers
- **Funding Trend Analysis**: Sector-specific funding patterns
- **Application Timing**: Optimal grant application periods
- **Success Predictors**: Factors correlating with grant awards

### **Technology Platform Features**

#### **1. User Interface & Experience**
- **Interactive Dashboard**: Real-time workflow monitoring and control
- **Configuration Management**: User-friendly setup and customization
- **Results Analysis**: Advanced filtering, sorting, and visualization
- **Report Generation**: Automated comprehensive reports and dossiers

#### **2. Workflow Management**
- **Automated Execution**: One-click research workflows
- **Progress Tracking**: Real-time status updates and notifications
- **Error Recovery**: Automatic retry and failure handling
- **Resumable Workflows**: Pause and continue long-running processes

#### **3. Data Management & Export**
- **Multiple Export Formats**: Excel, CSV, PDF, JSON
- **Data Versioning**: Track changes and maintain history
- **Backup & Recovery**: Automated data protection
- **API Access**: Programmatic data access for integration

---

## üèóÔ∏è **System Architecture Design**

### **Core Architectural Principles**

#### **1. Modularity & Extensibility**
- **Plugin Architecture**: Easy addition of new processing steps
- **Standardized Interfaces**: Consistent processor contracts
- **Configuration-Driven**: Modify behavior without code changes
- **Dependency Management**: Clear processor dependencies and execution order

#### **2. Scalability & Performance**
- **Asynchronous Processing**: Non-blocking I/O operations
- **Intelligent Caching**: Reduce API calls and processing time
- **Batch Processing**: Efficient handling of large datasets
- **Resource Management**: Memory and CPU optimization

#### **3. Reliability & Maintainability**
- **Comprehensive Error Handling**: Graceful failure recovery
- **Extensive Logging**: Detailed audit trails and debugging
- **Automated Testing**: Unit, integration, and end-to-end tests
- **Code Quality Standards**: Consistent formatting and documentation

#### **4. Security & Compliance**
- **API Key Management**: Secure credential storage
- **Data Privacy**: Appropriate handling of sensitive information
- **Access Control**: User-based permissions and restrictions
- **Audit Trails**: Complete operation logging

### **High-Level System Components**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     User Interface Layer                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Web Dashboard  ‚îÇ   CLI Tools     ‚îÇ    API Endpoints            ‚îÇ
‚îÇ  (Streamlit)    ‚îÇ   (Scripts)     ‚îÇ    (FastAPI)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Workflow Engine                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ State Manager   ‚îÇ Task Scheduler  ‚îÇ   Progress Monitor          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Processing Pipeline                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Lookup   ‚îÇ Filtering ‚îÇData Fetch ‚îÇ Analysis  ‚îÇ   Reporting     ‚îÇ
‚îÇProcessors ‚îÇProcessors ‚îÇProcessors ‚îÇProcessors ‚îÇ  Processors     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Data Layer                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Database      ‚îÇ  File Storage   ‚îÇ    External APIs            ‚îÇ
‚îÇ   (SQLite)      ‚îÇ  (Local Files)  ‚îÇ  (ProPublica, Grants.gov)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã **Detailed Requirements**

### **Functional Requirements**

#### **FR-1: Organization Discovery**
- **FR-1.1**: Accept EIN input for target organization analysis
- **FR-1.2**: Extract mission keywords from 990 filings
- **FR-1.3**: Match NTEE codes based on mission and activities
- **FR-1.4**: Generate prioritized list of similar organizations
- **FR-1.5**: Filter organizations by geographic, financial, and mission criteria

#### **FR-2: Data Collection & Processing**
- **FR-2.1**: Download and parse 990 XML and PDF filings
- **FR-2.2**: Extract financial data (revenue, assets, expenses, ratios)
- **FR-2.3**: Perform OCR on PDF documents when XML unavailable
- **FR-2.4**: Validate and clean extracted data
- **FR-2.5**: Cache processed data to avoid re-processing

#### **FR-3: Analysis & Scoring**
- **FR-3.1**: Calculate composite scores using configurable weights
- **FR-3.2**: Analyze financial trends over multiple years
- **FR-3.3**: Assess organizational stability and growth patterns
- **FR-3.4**: Evaluate mission alignment and program effectiveness
- **FR-3.5**: Generate risk assessments and sustainability scores

#### **FR-4: Relationship Mapping**
- **FR-4.1**: Extract board member information from filings
- **FR-4.2**: Identify shared board members across organizations
- **FR-4.3**: Analyze Schedule I grant patterns and relationships
- **FR-4.4**: Map geographic distribution and regional connections
- **FR-4.5**: Visualize relationship networks and influence patterns

#### **FR-5: Reporting & Export**
- **FR-5.1**: Generate comprehensive Excel dossiers for top prospects
- **FR-5.2**: Create summary reports with key findings and recommendations
- **FR-5.3**: Export data in multiple formats (CSV, JSON, PDF)
- **FR-5.4**: Provide interactive dashboard with filtering and sorting
- **FR-5.5**: Enable scheduled and automated report generation

### **Non-Functional Requirements**

#### **NFR-1: Performance**
- **NFR-1.1**: Process 500+ organizations in under 30 minutes
- **NFR-1.2**: Support concurrent processing of multiple workflows
- **NFR-1.3**: Maintain sub-5 second response times for dashboard interactions
- **NFR-1.4**: Efficiently handle large datasets (10,000+ organizations)
- **NFR-1.5**: Optimize memory usage for long-running processes

#### **NFR-2: Reliability**
- **NFR-2.1**: Achieve 99%+ workflow completion rate
- **NFR-2.2**: Implement automatic retry for transient failures
- **NFR-2.3**: Provide graceful degradation when external APIs unavailable
- **NFR-2.4**: Maintain data integrity across all operations
- **NFR-2.5**: Support workflow pause/resume functionality

#### **NFR-3: Usability**
- **NFR-3.1**: Enable non-technical users to configure and run workflows
- **NFR-3.2**: Provide clear progress indicators and status updates
- **NFR-3.3**: Offer intuitive navigation and workflow management
- **NFR-3.4**: Include comprehensive help documentation and tooltips
- **NFR-3.5**: Support multiple user preference and configuration profiles

#### **NFR-4: Maintainability**
- **NFR-4.1**: Achieve 90%+ code test coverage
- **NFR-4.2**: Enable addition of new processors within 4 hours
- **NFR-4.3**: Support configuration changes without code modification
- **NFR-4.4**: Provide comprehensive logging and debugging capabilities
- **NFR-4.5**: Maintain clear separation between business logic and infrastructure

### **Technical Constraints**

#### **TC-1: External Dependencies**
- **TC-1.1**: ProPublica API rate limits (unspecified, estimate 10 req/sec)
- **TC-1.2**: IRS data availability and update frequency
- **TC-1.3**: PDF processing limitations and accuracy constraints
- **TC-1.4**: OCR processing time and resource requirements

#### **TC-2: Development Environment**
- **TC-2.1**: Python 3.9+ compatibility requirement
- **TC-2.2**: VSCode and Claude Code development toolchain
- **TC-2.3**: Local development without Docker dependencies
- **TC-2.4**: Single-machine deployment model

#### **TC-3: Data & Privacy**
- **TC-3.1**: Public data sources only (no private/confidential data)
- **TC-3.2**: Compliance with API terms of service
- **TC-3.3**: Appropriate caching and storage of public information
- **TC-3.4**: Data retention and cleanup policies

---

## üìÖ **Implementation Roadmap**

### **Phase 1: Foundation (Weeks 1-2)**
**Goal**: Establish core architecture and migrate existing functionality

#### **Week 1: Project Setup & Core Architecture**
- Set up modern Python project structure
- Implement configuration management system
- Create base processor framework and workflow engine
- Establish logging, error handling, and testing frameworks
- Migrate and refactor EIN lookup processor (Step 0)

#### **Week 2: Core Data Pipeline**
- Migrate and enhance BMF filtering (Step 1)
- Migrate and improve ProPublica data fetching (Step 2)
- Implement basic financial scoring (Step 3)
- Create SQLite database schema and state management
- Develop basic CLI interface for testing

**Deliverables**:
- ‚úÖ Working core workflow engine
- ‚úÖ Migrated and improved Steps 0-3
- ‚úÖ Basic testing and validation framework
- ‚úÖ Configuration-driven operation

### **Phase 2: User Interface & Monitoring (Weeks 3-4)**
**Goal**: Create user-friendly interface and real-time monitoring

#### **Week 3: Dashboard Development**
- Build Streamlit dashboard with workflow monitoring
- Implement real-time progress tracking and notifications
- Create configuration management interface
- Develop results viewing and analysis tools
- Add basic data export functionality

#### **Week 4: Enhanced Data Collection**
- Migrate and improve XML/PDF downloaders (Step 4)
- Implement intelligent caching and retry logic
- Add OCR processing capabilities (Step 5)
- Create comprehensive error handling and recovery
- Develop API endpoints for external integration

**Deliverables**:
- ‚úÖ Full-featured dashboard interface
- ‚úÖ Complete data collection pipeline
- ‚úÖ Real-time monitoring and control
- ‚úÖ Robust error handling and recovery

### **Phase 3: Advanced Analysis (Weeks 5-6)**
**Goal**: Implement sophisticated analysis and relationship mapping

#### **Week 5: Enhanced Scoring & Analysis**
- Develop advanced composite scoring algorithms
- Implement multi-year trend analysis
- Create financial health and risk assessment
- Add mission alignment and similarity scoring
- Build configurable scoring profiles for different sectors

#### **Week 6: Relationship & Network Analysis**
- Implement board member extraction and analysis
- Create Schedule I grant flow analysis
- Develop geographic and regional analysis
- Build relationship visualization capabilities
- Add competitive intelligence features

**Deliverables**:
- ‚úÖ Advanced scoring and ranking system
- ‚úÖ Relationship mapping and network analysis
- ‚úÖ Multi-dimensional analysis capabilities
- ‚úÖ Enhanced intelligence and insights

### **Phase 4: Reporting & Integration (Weeks 7-8)**
**Goal**: Professional reporting and external integration capabilities

#### **Week 7: Advanced Reporting**
- Create comprehensive Excel dossier generation
- Develop PDF report templates and generation
- Build interactive data visualization components
- Implement scheduled and automated reporting
- Add report customization and templating

#### **Week 8: Integration & Polish**
- Develop API endpoints for external integration
- Implement data import/export capabilities
- Add user preference and configuration management
- Create comprehensive documentation and help system
- Perform end-to-end testing and optimization

**Deliverables**:
- ‚úÖ Professional reporting capabilities
- ‚úÖ External integration APIs
- ‚úÖ Comprehensive documentation
- ‚úÖ Production-ready system

### **Phase 5: Optimization & Deployment (Week 9)**
**Goal**: Performance optimization and deployment preparation

#### **Week 9: Final Polish**
- Performance testing and optimization
- Security review and hardening
- User acceptance testing and feedback incorporation
- Deployment documentation and procedures
- Training materials and user guides

**Deliverables**:
- ‚úÖ Optimized and tested system
- ‚úÖ Deployment-ready package
- ‚úÖ Complete documentation suite
- ‚úÖ User training materials

---

## üéØ **Success Criteria & KPIs**

### **Technical Success Metrics**
- **Workflow Completion Rate**: >95% successful completion
- **Processing Speed**: 500+ organizations analyzed in <30 minutes
- **Dashboard Response Time**: <5 seconds for all interactions
- **Code Coverage**: >90% test coverage across all modules
- **Error Recovery**: <5% manual intervention rate

### **User Experience Metrics**
- **Setup Time**: <30 minutes from installation to first workflow
- **Learning Curve**: Non-technical users productive within 2 hours
- **Configuration Flexibility**: 80% of use cases achievable through UI
- **Report Quality**: Professional reports requiring <10% manual editing

### **Business Impact Metrics**
- **Research Efficiency**: 80% reduction in manual research time
- **Discovery Rate**: 50% increase in potential funder identification
- **Decision Quality**: Quantified scoring enables data-driven decisions
- **Scalability**: Support 5x increase in research volume with same resources

---

## üîÑ **Risk Management**

### **Technical Risks**
- **API Limitations**: Mitigation through caching, rate limiting, and fallback strategies
- **Data Quality Issues**: Validation, cleaning, and manual review processes
- **Performance Bottlenecks**: Profiling, optimization, and architectural improvements
- **External Dependencies**: Graceful degradation and alternative data sources

### **Project Risks**
- **Scope Creep**: Strict phase-based delivery and feature prioritization
- **Timeline Pressure**: MVP-focused development with incremental enhancement
- **Resource Constraints**: Clear dependency management and parallel development
- **User Adoption**: Early stakeholder involvement and iterative feedback

### **Operational Risks**
- **Data Privacy**: Compliance review and appropriate data handling procedures
- **System Reliability**: Comprehensive testing and monitoring capabilities
- **Maintenance Burden**: Automated testing and clear documentation standards
- **Knowledge Transfer**: Code documentation and architectural decision records

---

## üìù **Design Decision Records**

### **DDR-001: Technology Stack Selection**
**Decision**: Use Python 3.9+ with Streamlit, FastAPI, and SQLite
**Context**: Need modern, maintainable technology stack for rapid development
**Consequences**: Faster development, easier maintenance, good performance for target scale
**Alternatives Considered**: Django + React, Flask + Vue.js, Full Node.js stack

### **DDR-002: Architecture Pattern**
**Decision**: Modular processor pipeline with plugin architecture
**Context**: Need extensible system that can grow and adapt to new requirements
**Consequences**: Easy to add new features, clear separation of concerns, testable components
**Alternatives Considered**: Monolithic application, Microservices architecture

### **DDR-003: State Management**
**Decision**: SQLite database with JSON file fallback for workflow state
**Context**: Need persistent state management without complex infrastructure
**Consequences**: Simple deployment, good performance, limited scalability
**Alternatives Considered**: PostgreSQL, Redis, File-based only

### **DDR-004: Development Environment**
**Decision**: VSCode + Claude Code + Local Python (no Docker)
**Context**: Reduce complexity and improve development experience
**Consequences**: Faster development cycles, easier debugging, environment consistency challenges
**Alternatives Considered**: Continue with Docker, PyCharm IDE, Jupyter notebooks

---

## üîç **Quality Assurance Strategy**

### **Testing Strategy**
- **Unit Tests**: Individual processor and utility function testing
- **Integration Tests**: End-to-end workflow testing with mock data
- **Performance Tests**: Load testing with large datasets
- **User Acceptance Tests**: Real-world scenario validation

### **Code Quality Standards**
- **Code Coverage**: Minimum 90% coverage for core modules
- **Documentation**: Comprehensive docstrings and API documentation
- **Code Review**: Peer review process for all changes
- **Static Analysis**: Automated linting and type checking

### **Monitoring & Observability**
- **Application Logs**: Structured logging with appropriate levels
- **Performance Metrics**: Response times, throughput, error rates
- **Business Metrics**: Workflow success rates, data quality measures
- **Health Checks**: System health monitoring and alerting

---

## üìö **Documentation Strategy**

### **User Documentation**
- **User Guide**: Step-by-step instructions for common workflows
- **Configuration Guide**: How to customize settings and scoring profiles
- **Troubleshooting Guide**: Common issues and solutions
- **Video Tutorials**: Screen recordings for complex procedures

### **Developer Documentation**
- **API Reference**: Complete API endpoint documentation
- **Processor Development Guide**: How to create new processors
- **Architecture Overview**: System design and component relationships
- **Deployment Guide**: Installation and deployment procedures

### **Operational Documentation**
- **Maintenance Procedures**: Regular maintenance tasks and schedules
- **Backup and Recovery**: Data protection and disaster recovery
- **Performance Tuning**: Optimization guidelines and best practices
- **Security Guidelines**: Security considerations and compliance

---

## üéØ **Acceptance Criteria**

### **Phase 1 Acceptance (Foundation)**
- [ ] All existing scripts successfully migrated and functional
- [ ] Workflow engine can execute processors in correct dependency order
- [ ] Configuration system supports environment variables and file-based config
- [ ] Basic error handling and logging implemented across all components
- [ ] SQLite database schema created and state management working
- [ ] Unit tests written for core components with >80% coverage

### **Phase 2 Acceptance (User Interface)**
- [ ] Streamlit dashboard displays real-time workflow progress
- [ ] Users can configure and start workflows through web interface
- [ ] Results can be viewed, filtered, and sorted through dashboard
- [ ] Basic data export functionality (CSV) working
- [ ] Error messages and status updates clearly displayed to users
- [ ] Dashboard responsive and usable on different screen sizes

### **Phase 3 Acceptance (Advanced Analysis)**
- [ ] Enhanced scoring algorithm with configurable weights implemented
- [ ] Multi-year trend analysis functional and accurate
- [ ] Board member extraction and relationship mapping working
- [ ] Schedule I grant analysis identifies funding patterns
- [ ] Geographic analysis provides meaningful regional insights
- [ ] Performance acceptable for processing 500+ organizations

### **Phase 4 Acceptance (Reporting & Integration)**
- [ ] Excel dossier generation produces professional-quality reports
- [ ] PDF summary reports generated with key findings
- [ ] API endpoints functional and properly documented
- [ ] Data import/export supports multiple formats
- [ ] Automated report scheduling and delivery working
- [ ] System can integrate with external tools via API

### **Final Acceptance (Production Ready)**
- [ ] System processes real-world datasets without errors
- [ ] Performance meets all specified benchmarks
- [ ] Security review completed with no critical issues
- [ ] User acceptance testing completed with stakeholder approval
- [ ] Complete documentation suite available and reviewed
- [ ] Deployment procedures tested and validated

---

## üöÄ **Next Steps & Action Items**

### **Immediate Actions (Week 1)**
1. **Environment Setup**
   - [ ] Install VSCode with recommended extensions
   - [ ] Set up Python virtual environment
   - [ ] Create basic project structure
   - [ ] Configure Git repository and initial commit

2. **Foundation Development**
   - [ ] Implement basic configuration management
   - [ ] Create base processor framework
   - [ ] Set up logging and error handling
   - [ ] Migrate EIN lookup processor as proof of concept

3. **Planning & Design**
   - [ ] Finalize processor migration strategy
   - [ ] Create detailed task breakdown for Phase 1
   - [ ] Set up development workflow and standards
   - [ ] Establish testing and quality assurance procedures

### **Week 2-3 Priorities**
- Complete core processor migration
- Implement workflow engine and state management
- Begin dashboard development
- Establish comprehensive testing framework

### **Stakeholder Communication**
- Weekly progress updates with demo of working functionality
- Regular feedback sessions on user interface design
- Monthly review of project scope and timeline
- Continuous validation of requirements and priorities

---

## üéØ **Success Measurement Framework**

### **Development Velocity Metrics**
- **Story Points Completed**: Track development progress against plan
- **Code Quality Metrics**: Monitor test coverage, complexity, and maintainability
- **Bug Discovery Rate**: Track defects found during development vs. production
- **Feature Completion Rate**: Measure actual vs. planned feature delivery

### **System Performance Metrics**
- **Workflow Completion Time**: Average time to process standard datasets
- **Error Rates**: Percentage of workflows that fail or require intervention
- **Resource Utilization**: CPU, memory, and storage usage patterns
- **API Response Times**: Performance of all system interfaces

### **User Adoption Metrics**
- **Time to First Success**: How quickly new users can complete a workflow
- **Feature Utilization**: Which features are used most/least frequently
- **User Satisfaction**: Feedback scores and usability assessments
- **Support Request Volume**: Frequency and types of user support needs

### **Business Impact Metrics**
- **Research Efficiency**: Time savings compared to manual processes
- **Discovery Quality**: Number of high-quality prospects identified
- **Decision Support**: Percentage of decisions supported by system data
- **ROI Calculation**: Cost savings and value generation measurements

---

This comprehensive design document provides the strategic foundation, detailed requirements, and implementation roadmap for rebuilding the Grant Research Automation platform. It balances technical excellence with practical delivery considerations, ensuring a successful transition from the current Docker-based system to a modern, maintainable, and extensible platform.

The modular architecture, phased implementation approach, and comprehensive quality assurance strategy minimize risk while maximizing value delivery at each stage of development. Regular stakeholder engagement and measurable success criteria ensure the final system meets both technical and business objectives.
import logging
from pathlib import Path

from src.core.data_models import ProcessorConfig, ProcessorResult
from src.utils.decorators import retry_on_failure, log_execution_time
from src.utils.validators import validate_ein

@dataclass
class ProcessorMetadata:
    """Metadata about a processor's capabilities and requirements."""
    name: str
    description: str
    version: str
    dependencies: List[str]  # List of required processor names
    estimated_duration: int  # Estimated seconds for execution
    requires_network: bool = False
    requires_api_key: bool = False

class BaseProcessor(ABC):
    """
    Abstract base class for all workflow processors.
    
    Provides common functionality:
    - Logging and error handling
    - Input validation
    - Progress tracking
    - Cleanup operations
    - Standardized result format
    """
    
    def __init__(self, metadata: ProcessorMetadata):
        self.metadata = metadata
        self.logger = logging.getLogger(f"processors.{metadata.name}")
        self._start_time: Optional[datetime] = None
        self._progress_callback: Optional[callable] = None
    
    def set_progress_callback(self, callback: callable):
        """Set callback function for progress updates."""
        self._progress_callback = callback
    
    def _update_progress(self, current: int, total: int, message: str = ""):
        """Update progress if callback is set."""
        if self._progress_callback:
            self._progress_callback(current, total, message)
    
    @abstractmethod
    def execute(self, config: ProcessorConfig, workflow_id: str) -> ProcessorResult:
        """
        Execute the main processing logic.
        
        Args:
            config: Configuration object with all necessary parameters
            workflow_id: Unique identifier for this workflow run
            
        Returns:
            ProcessorResult with success/failure status and any output data
        """
        pass
    
    def validate_inputs(self, config: ProcessorConfig) -> List[str]:
        """
        Validate inputs before execution.
        
        Returns:
            List of validation error messages (empty if valid)
        """
        errors = []
        
        # Common validations
        if hasattr(config, 'ein') and config.ein:
            if not validate_ein(config.ein):
                errors.append(f"Invalid EIN format: {config.ein}")
        
        return errors
    
    def validate_dependencies(self, workflow_state: Dict[str, Any]) -> List[str]:
        """
        Check if all required dependencies have completed successfully.
        
        Returns:
            List of missing dependencies
        """
        missing = []
        for dep in self.metadata.dependencies:
            if dep not in workflow_state or workflow_state[dep].get('status') != 'success':
                missing.append(dep)
        return missing
    
    @log_execution_time
    @retry_on_failure(max_attempts=3, delay=1.0)
    def run(self, config: ProcessorConfig, workflow_id: str) -> ProcessorResult:
        """
        Main entry point with error handling and logging.
        """
        self._start_time = datetime.now()
        self.logger.info(f"Starting {self.metadata.name} for workflow {workflow_id}")
        
        try:
            # Pre-execution validation
            validation_errors = self.validate_inputs(config)
            if validation_errors:
                return ProcessorResult(
                    success=False,
                    errors=validation_errors,
                    processor_name=self.metadata.name
                )
            
            # Execute main logic
            result = self.execute(config, workflow_id)
            
            # Post-execution logging
            duration = (datetime.now() - self._start_time).total_seconds()
            self.logger.info(f"Completed {self.metadata.name} in {duration:.2f}s")
            
            return result
            
        except Exception as e:
            self.logger.error(f"Error in {self.metadata.name}: {str(e)}", exc_info=True)
            return ProcessorResult(
                success=False,
                errors=[f"Unexpected error: {str(e)}"],
                processor_name=self.metadata.name
            )
        finally:
            self.cleanup(workflow_id)
    
    def cleanup(self, workflow_id: str):
        """Cleanup resources after execution (override if needed)."""
        pass
```

### **3. Enhanced Data Models with Better Type Safety**
```python
# src/core/data_models.py
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Any, Optional, Union
from datetime import datetime
from enum import Enum
import re

class WorkflowStatus(str, Enum):
    """Enumeration of possible workflow states."""
    PENDING = "pending"
    RUNNING = "running" 
    COMPLETED = "completed"
    FAILED = "failed"
    PAUSED = "paused"
    CANCELLED = "cancelled"

class ProcessorResult(BaseModel):
    """Standard result format for all processors."""
    success: bool
    processor_name: str
    execution_time: Optional[float] = None
    data: Dict[str, Any] = Field(default_factory=dict)
    errors: List[str] = Field(default_factory=list)
    warnings: List[str] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    created_at: datetime = Field(default_factory=datetime.now)

class OrganizationProfile(BaseModel):
    """Comprehensive organization data model."""
    ein: str = Field(..., description="9-digit EIN")
    name: str
    ntee_code: Optional[str] = None
    state: str
    
    # Financial Data
    revenue: Optional[float] = None
    assets: Optional[float] = None
    expenses: Optional[float] = None
    program_expense_ratio: Optional[float] = None
    
    # Organizational Data
    mission_description: Optional[str] = None
    activity_description: Optional[str] = None
    board_members: List[str] = Field(default_factory=list)
    key_personnel: List[Dict[str, Any]] = Field(default_factory=list)
    
    # Filing Information
    most_recent_filing_year: Optional[int] = None
    filing_years: List[int] = Field(default_factory=list)
    filing_consistency_score: Optional[float] = None
    
    # Scoring Data
    composite_score: Optional[float] = None
    component_scores: Dict[str, float] = Field(default_factory=dict)
    score_rank: Optional[int] = None
    
    # Metadata
    last_updated: datetime = Field(default_factory=datetime.now)
    data_sources: List[str] = Field(default_factory=list)
    
    @validator('ein')
    def validate_ein_format(cls, v):
        """Ensure EIN is properly formatted."""
        if not re.match(r'^\d{9}$', v):
            raise ValueError('EIN must be exactly 9 digits')
        return v
    
    @validator('program_expense_ratio')
    def validate_expense_ratio(cls, v):
        """Ensure expense ratio is between 0 and 1."""
        if v is not None and (v < 0 or v > 1):
            raise ValueError('Program expense ratio must be between 0 and 1')
        return v

class WorkflowConfig(BaseModel):
    """Configuration for a complete workflow run."""
    workflow_id: str = Field(default_factory=lambda: f"workflow_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    
    # Target Configuration
    target_ein: Optional[str] = None
    target_organization_name: Optional[str] = None
    
    # Filtering Criteria
    ntee_codes: List[str] = Field(default_factory=lambda: ["P81", "E31", "W70"])
    state_filter: str = "VA"
    min_revenue: int = 100000
    max_revenue: Optional[int] = None
    min_assets: Optional[int] = None
    
    # Processing Options
    max_results: int = 100
    scoring_profile: str = "default"
    processors_to_run: List[str] = Field(default_factory=list)  # Empty = run all
    
    # Output Options
    generate_excel_dossier: bool = True
    generate_pdf_report: bool = False
    include_board_analysis: bool = True
    include_financial_trends: bool = True
    
    # Performance Settings
    max_concurrent_downloads: int = 3
    enable_caching: bool = True
    
    class Config:
        schema_extra = {
            "example": {
                "ntee_codes": ["P81", "E31"],
                "state_filter": "VA", 
                "min_revenue": 100000,
                "max_results": 50,
                "generate_excel_dossier": True
            }
        }
```

---

## üöÄ **Workflow Engine Architecture**

### **Enhanced Workflow Engine with Real-time Updates**
```python
# src/core/workflow_engine.py
import asyncio
from typing import Dict, List, Optional, Callable
from datetime import datetime
import logging

from src.core.data_models import WorkflowConfig, WorkflowStatus, ProcessorResult
from src.core.state_manager import StateManager
from src.processors import get_processor, list_processors
from src.utils.logging import get_logger

class WorkflowEngine:
    """
    Core workflow orchestration engine.
    
    Features:
    - Asynchronous execution with progress tracking
    - Automatic dependency resolution
    - Error recovery and retry logic
    - Real-time status updates
    - Workflow pause/resume capability
    """
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.state_manager = StateManager()
        self.status_callbacks: List[Callable] = []
        self.running_workflows: Dict[str, bool] = {}
    
    def add_status_callback(self, callback: Callable):
        """Add callback for workflow status updates."""
        self.status_callbacks.append(callback)
    
    def _notify_status_change(self, workflow_id: str, status: WorkflowStatus, data: Dict = None):
        """Notify all registered callbacks of status changes."""
        for callback in self.status_callbacks:
            try:
                callback(workflow_id, status, data or {})
            except Exception as e:
                self.logger.error(f"Error in status callback: {e}")
    
    async def run_workflow(self, config: WorkflowConfig) -> Dict[str, Any]:
        """
        Execute a complete workflow asynchronously.
        
        Args:
            config: Workflow configuration
            
        Returns:
            Dictionary with workflow results and metadata
        """
        workflow_id = config.workflow_id
        self.running_workflows[workflow_id] = True
        
        try:
            self.logger.info(f"Starting workflow {workflow_id}")
            self._notify_status_change(workflow_id, WorkflowStatus.RUNNING)
            
            # Initialize workflow state
            self.state_manager.create_workflow(workflow_id, config)
            
            # Determine processor execution order
            processors_to_run = config.processors_to_run or list_processors()
            execution_order = self._resolve_dependencies(processors_to_run)
            
            results = {}
            
            for processor_name in execution_order:
                # Check if workflow was cancelled
                if not self.running_workflows.get(workflow_id, False):
                    self.logger.info(f"Workflow {workflow_id} was cancelled")
                    self._notify_status_change(workflow_id, WorkflowStatus.CANCELLED)
                    return {"status": "cancelled", "results": results}
                
                # Skip if already completed (for resumable workflows)
                if self.state_manager.is_step_complete(workflow_id, processor_name):
                    self.logger.info(f"Skipping completed step: {processor_name}")
                    continue
                
                processor = get_processor(processor_name)
                if not processor:
                    error_msg = f"Processor not found: {processor_name}"
                    self.logger.error(error_msg)
                    results[processor_name] = ProcessorResult(
                        success=False,
                        processor_name=processor_name,
                        errors=[error_msg]
                    )
                    continue
                
                self.logger.info(f"Executing processor: {processor_name}")
                
                # Execute processor
                result = await asyncio.to_thread(
                    processor.run,
                    config,
                    workflow_id
                )
                
                results[processor_name] = result
                
                # Save step result
                self.state_manager.save_step_result(workflow_id, processor_name, result)
                
                # Notify progress
                progress = {
                    "current_step": processor_name,
                    "completed_steps": len([r for r in results.values() if r.success]),
                    "total_steps": len(execution_order),
                    "step_result": result.dict()
                }
                self._notify_status_change(workflow_id, WorkflowStatus.RUNNING, progress)
                
                # Stop on critical failure
                if not result.success and processor_name in ["ein_lookup", "bmf_filter"]:
                    self.logger.error(f"Critical processor failed: {processor_name}")
                    self._notify_status_change(workflow_id, WorkflowStatus.FAILED)
                    return {"status": "failed", "results": results}
            
            # Mark workflow as completed
            self.state_manager.mark_workflow_complete(workflow_id)
            self._notify_status_change(workflow_id, WorkflowStatus.COMPLETED)
            
            self.logger.info(f"Workflow {workflow_id} completed successfully")
            return {"status": "completed", "results": results}
            
        except Exception as e:
            self.logger.error(f"Workflow {workflow_id} failed: {str(e)}", exc_info=True)
            self.state_manager.mark_workflow_failed(workflow_id, str(e))
            self._notify_status_change(workflow_id, WorkflowStatus.FAILED)
            return {"status": "failed", "error": str(e)}
        finally:
            self.running_workflows.pop(workflow_id, None)
    
    def cancel_workflow(self, workflow_id: str) -> bool:
        """Cancel a running workflow."""
        if workflow_id in self.running_workflows:
            self.running_workflows[workflow_id] = False
            self.logger.info(f"Cancellation requested for workflow {workflow_id}")
            return True
        return False
    
    def _resolve_dependencies(self, processor_names: List[str]) -> List[str]:
        """
        Resolve processor dependencies and return execution order.
        
        Uses topological sorting to ensure dependencies run first.
        """
        # Implementation of dependency resolution
        # For now, return the standard order based on your existing scripts
        standard_order = [
            "ein_lookup",           # Step 0
            "bmf_filter",           # Step 1  
            "propublica_fetch",     # Step 2
            "financial_scorer",     # Step 3
            "xml_downloader",       # Step 4a
            "pdf_downloader",       # Step 4b
            "pdf_ocr",             # Step 5
            "board_analyzer",       # Additional analysis
            "report_generator"      # Final reporting
        ]
        
        # Filter to only requested processors
        if processor_names:
            return [p for p in standard_order if p in processor_names]
        return standard_order
```

---

## üéõÔ∏è **Modern Dashboard with VSCode Integration**

### **Enhanced Streamlit Dashboard**
```python
# src/dashboard/app.py
import streamlit as st
import asyncio
from datetime import datetime
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

from src.config.settings import settings
from src.core.workflow_engine import WorkflowEngine
from src.core.data_models import WorkflowConfig
from src.dashboard.utils.api_client import APIClient
from src.dashboard.components.progress_indicators import WorkflowProgressBar
from src.dashboard.components.data_tables import ScoredOrganizationsTable

# Configure Streamlit page
st.set_page_config(
    page_title="Grant Research Automation",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .success-card {
        border-left-color: #2e8b57;
    }
    .warning-card {
        border-left-color: #ff6b35;
    }
    .error-card {
        border-left-color: #dc3545;
    }
</style>
""", unsafe_allow_html=True)

class GrantResearchDashboard:
    """Main dashboard application class."""
    
    def __init__(self):
        self.api_client = APIClient(settings.api_base_url)
        self.workflow_engine = WorkflowEngine()
        
        # Initialize session state
        if 'workflow_status' not in st.session_state:
            st.session_state.workflow_status = {}
        if 'current_workflow_id' not in st.session_state:
            st.session_state.current_workflow_id = None
    
    def render_sidebar(self):
        """Render navigation sidebar."""
        with st.sidebar:
            st.title("üéØ Grant Research")
            st.markdown("---")
            
            # Quick stats
            st.subheader("Quick Stats")
            try:
                stats = self.api_client.get_workflow_stats()
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Active Workflows", stats.get('active', 0))
                with col2:
                    st.metric("Completed Today", stats.get('completed_today', 0))
            except Exception as e:
                st.error(f"Error loading stats: {e}")
            
            st.markdown("---")
            
            # Navigation
            st.subheader("Navigation")
            pages = {
                "üè† Dashboard": "dashboard",
                "‚ñ∂Ô∏è New Workflow": "new_workflow", 
                "üìä Results": "results",
                "‚öôÔ∏è Configuration": "configuration",
                "üìÑ Reports": "reports",
                "üîç Research": "research"
            }
            
            selected_page = st.radio("Go to", list(pages.keys()), key="navigation")
            return pages[selected_page]
    
    def render_dashboard_page(self):
        """Main dashboard overview page."""
        st.title("üéØ Grant Research Automation Dashboard")
        
        # Workflow status overview
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown("""
            <div class="metric-card success-card">
                <h3>Completed</h3>
                <h2>12</h2>
                <p>This month</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="metric-card">
                <h3>In Progress</h3>
                <h2>3</h2>
                <p>Active workflows</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div class="metric-card warning-card">
                <h3>Organizations</h3>
                <h2>1,247</h2>
                <p>Analyzed total</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            st.markdown("""
            <div class="metric-card">
                <h3>Success Rate</h3>
                <h2>94%</h2>
                <p>Workflow completion</p>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Recent workflow activity
        st.subheader("Recent Workflow Activity")
        
        # Get recent workflows from API
        try:
            recent_workflows = self.api_client.get_recent_workflows(limit=10)
            if recent_workflows:
                df = pd.DataFrame(recent_workflows)
                
                # Status color mapping
                status_colors = {
                    'completed': 'üü¢',
                    'running': 'üîµ', 
                    'failed': 'üî¥',
                    'pending': 'üü°'
                }
                
                # Add status icons
                df['Status'] = df['status'].map(status_colors) + ' ' + df['status'].str.title()
                
                # Display table
                st.dataframe(
                    df[['workflow_id', 'Status', 'start_time', 'organizations_processed']],
                    use_container_width=True,
                    hide_index=True
                )
            else:
                st.info("No recent workflows found. Create a new workflow to get started!")
        except Exception as e:
            st.error(f"Error loading recent workflows: {e}")
        
        # Quick actions
        st.subheader("Quick Actions")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("üöÄ Start New Workflow", use_container_width=True):
                st.session_state.navigation = "new_workflow"
                st.rerun()
        
        with col2:
            if st.button("üìä View Results", use_container_width=True):
                st.session_state.navigation = "results"
                st.rerun()
        
        with col3:
            if st.button("üìÑ Generate Report", use_container_width=True):
                st.session_state.navigation = "reports"
                st.rerun()
        
        with col4:
            if st.button("‚öôÔ∏è Settings", use_container_width=True):
                st.session_state.navigation = "configuration"
                st.rerun()
    
    def render_new_workflow_page(self):
        """New workflow creation page."""
        st.title("üöÄ Create New Workflow")
        
        with st.form("new_workflow_form"):
            st.subheader("Workflow Configuration")
            
            # Basic settings
            col1, col2 = st.columns(2)
            
            with col1:
                workflow_name = st.text_input(
                    "Workflow Name",
                    value=f"Research_{datetime.now().strftime('%Y%m%d_%H%M')}"
                )
                
                target_ein = st.text_input(
                    "Target EIN (Optional)",
                    help="9-digit EIN to analyze similar organizations"
                )
                
                state_filter = st.selectbox(
                    "State Filter",
                    ["VA", "MD", "DC", "NC", "WV", "All States"],
                    index=0
                )
            
            with col2:
                min_revenue = st.number_input(
                    "Minimum Revenue ($)",
                    min_value=0,
                    value=100000,
                    step=10000
                )
                
                max_results = st.number_input(
                    "Maximum Results",
                    min_value=10,
                    max_value=1000,
                    value=100,
                    step=10
                )
                
                scoring_profile = st.selectbox(
                    "Scoring Profile",
                    ["default", "health_focused", "education_focused", "social_services"]
                )
            
            # NTEE Code selection
            st.subheader("NTEE Code Filters")
            ntee_options = {
                "P81 - Health - General": "P81",
                "E31 - Health - Hospitals": "E31", 
                "W70 - Public Safety": "W70",
                "B25 - Education - Higher Ed": "B25",
                "P30 - Health - Mental Health": "P30"
            }
            
            selected_ntee = st.multiselect(
                "Select NTEE Codes",
                options=list(ntee_options.keys()),
                default=["P81 - Health - General", "E31 - Health - Hospitals"]
            )
            
            # Processing options
            st.subheader("Processing Options")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                download_xml = st.checkbox("Download XML Filings", value=True)
                download_pdf = st.checkbox("Download PDF Filings", value=True)
            
            with col2:
                run_ocr = st.checkbox("Run OCR on PDFs", value=False)
                board_analysis = st.checkbox("Analyze Board Members", value=True)
            
            with col3:
                generate_excel = st.checkbox("Generate Excel Dossier", value=True)
                trend_analysis = st.checkbox("Multi-year Trend Analysis", value=True)
            
            submitted = st.form_submit_button("üöÄ Start Workflow", use_container_width=True)
            
            if submitted:
                # Build workflow config
                config = WorkflowConfig(
                    target_ein=target_ein if target_ein else None,
                    ntee_codes=[ntee_options[name] for name in selected_ntee],
                    state_filter=state_filter if state_filter != "All States" else None,
                    min_revenue=min_revenue,
                    max_results=max_results,
                    scoring_profile=scoring_profile,
                    generate_excel_dossier=generate_excel,
                    include_board_analysis=board_analysis
                )
                
                try:
                    # Start workflow via API
                    response = self.api_client.start_workflow(config.dict())
                    workflow_id = response['workflow_id']
                    
                    st.success(f"‚úÖ Workflow started successfully!")
                    st.info(f"Workflow ID: {workflow_id}")
                    
                    # Store workflow ID in session state
                    st.session_state.current_workflow_id = workflow_id
                    
                    # Redirect to monitoring
                    time.sleep(2)
                    st.session_state.navigation = "dashboard"
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"‚ùå Error starting workflow: {e}")
    
    def render_results_page(self):
        """Results analysis and viewing page."""
        st.title("üìä Workflow Results")
        
        # Workflow selector
        workflows = self.api_client.get_completed_workflows()
        if not workflows:
            st.warning("No completed workflows found.")
            return
        
        selected_workflow = st.selectbox(
            "Select Workflow",
            options=[w['workflow_id'] for w in workflows],
            format_func=lambda x: f"{x} ({next(w['start_time'] for w in workflows if w['workflow_id'] == x)})"
        )
        
        if selected_workflow:
            # Load workflow results
            results = self.api_client.get_workflow_results(selected_workflow)
            
            # Results summary
            st.subheader("Results Summary")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Organizations Found", results.get('total_organizations', 0))
            with col2:
                st.metric("Scored Organizations", results.get('scored_organizations', 0))
            with col3:
                st.metric("Top Score", f"{results.get('top_score', 0):.3f}")
            with col4:
                avg_score = results.get('average_score', 0)
                st.metric("Average Score", f"{avg_score:.3f}")
            
            # Score distribution chart
            if 'organizations' in results:
                df = pd.DataFrame(results['organizations'])
                
                fig = px.histogram(
                    df, 
                    x='composite_score',
                    nbins=20,
                    title="Score Distribution",
                    labels={'composite_score': 'Composite Score', 'count': 'Number of Organizations'}
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Top organizations table
                st.subheader("Top Scoring Organizations")
                top_orgs = df.nlargest(20, 'composite_score')
                
                # Format for display
                display_cols = ['name', 'state', 'composite_score', 'avg_revenue', 'most_recent_year']
                if all(col in top_orgs.columns for col in display_cols):
                    formatted_df = top_orgs[display_cols].copy()
                    formatted_df['avg_revenue'] = formatted_df['avg_revenue'].apply(
                        lambda x: f"${x:,.0f}" if pd.notnull(x) else "N/A"
                    )
                    formatted_df['composite_score'] = formatted_df['composite_score'].apply(
                        lambda x: f"{x:.3f}"
                    )
                    
                    st.dataframe(formatted_df, use_container_width=True, hide_index=True)
                
                # Download options
                st.subheader("Export Results")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    csv = df.to_csv(index=False)
                    st.download_button(
                        "üìÑ Download CSV",
                        csv,
                        f"results_{selected_workflow}.csv",
                        "text/csv"
                    )
                
                with col2:
                    if st.button("üìä Generate Excel Report"):
                        excel_path = self.api_client.generate_excel_report(selected_workflow)
                        st.success(f"Excel report generated: {excel_path}")
                
                with col3:
                    if st.button("üìã Generate Summary Report"):
                        pdf_path = self.api_client.generate_summary_report(selected_workflow)
                        st.success(f"Summary report generated: {pdf_path}")

def main():
    """Main application entry point."""
    dashboard = GrantResearchDashboard()
    
    # Render sidebar and get selected page
    selected_page = dashboard.render_sidebar()
    
    # Render selected page
    if selected_page == "dashboard":
        dashboard.render_dashboard_page()
    elif selected_page == "new_workflow":
        dashboard.render_new_workflow_page()
    elif selected_page == "results":
        dashboard.render_results_page()
    elif selected_page == "configuration":
        st.title("‚öôÔ∏è Configuration")
        st.info("Configuration page coming soon!")
    elif selected_page == "reports":
        st.title("üìÑ Reports")
        st.info("Reports page coming soon!")
    elif selected_page == "research":
        st.title("üîç Research")
        st.info("Research workspace coming soon!")

if __name__ == "__main__":
    main()
```

---

## üõ†Ô∏è **VSCode Development Setup**

### **VSCode Workspace Configuration**
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./grant-research-env/bin/python",
    "python.formatting.provider": "black",
    "python.formatting.blackArgs": ["--line-length", "88"],
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true,
    "python.linting.mypyEnabled": true,
    "python.testing.pytestEnabled": true,
    "python.testing.unittestEnabled": false,
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    },
    "files.associations": {
        "*.py": "python"
    },
    "python.linting.pylintArgs": [
        "--load-plugins=pylint_django",
        "--disable=C0114,C0115,C0116"  // Disable docstring warnings for development
    ]
}
```

### **Debug Configuration**
```json
// .vscode/launch.json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Main Application",
            "type": "python",
            "request": "launch", 
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "Streamlit Dashboard",
            "type": "python",
            "request": "launch",
            "module": "streamlit",
            "args": ["run", "src/dashboard/app.py"],
            "console": "integratedTerminal",
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "Single Processor Test",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/scripts/test_processor.py",
            "args": ["${input:processorName}"],
            "console": "integratedTerminal"
        },
        {
            "name": "Flask API Server",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/src/api/app.py",
            "console": "integratedTerminal",
            "envFile": "${workspaceFolder}/.env"
        }
    ],
    "inputs": [
        {
            "id": "processorName",
            "description": "Processor name to test",
            "default": "ein_lookup",
            "type": "promptString"
        }
    ]
}
```

### **Modern Project Configuration**
```toml
# pyproject.toml
[build-system]
requires = ["setuptools>=45", "wheel", "setuptools_scm[toml]>=6.2"]
build-backend = "setuptools.build_meta"

[project]
name = "grant-research-automation"
version = "2.0.0"
description = "Comprehensive grant research and analysis automation platform"
authors = [{name = "Your Name", email = "your.email@example.com"}]
license = {text = "MIT"}
readme = "README.md"
requires-python = ">=3.9"
keywords = ["grants", "nonprofits", "research", "automation", "990"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: End Users/Desktop",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
]

dependencies = [
    "pydantic>=2.0.0",
    "pydantic-settings>=2.0.0",
    "pandas>=2.0.0",
    "requests>=2.28.0",
    "streamlit>=1.28.0",
    "plotly>=5.0.0",
    "openpyxl>=3.1.0",
    "beautifulsoup4>=4.12.0",
    "lxml>=4.9.0",
    "pdf2image>=3.1.0",
    "pytesseract>=0.3.10",
    "SQLAlchemy>=2.0.0",
    "alembic>=1.12.0",
    "fastapi>=0.100.0",
    "uvicorn>=0.20.0",
    "python-multipart>=0.0.6",
    "jinja2>=3.1.0",
    "aiofiles>=23.0.0",
    "httpx>=0.24.0"
]

[project.optional-dependencies]
dev = [
    "black>=23.0.0",
    "isort>=5.12.0", 
    "pylint>=2.17.0",
    "mypy>=1.5.0",
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-asyncio>=0.21.0",
    "pre-commit>=3.4.0"
]

[project.urls]
Homepage = "https://github.com/yourusername/grant-research-automation"
Repository = "https://github.com/yourusername/grant-research-automation.git"
Issues = "https://github.com/yourusername/grant-research-automation/issues"

[project.scripts]
grant-research = "src.main:main"
grant-dashboard = "src.dashboard.app:main"

[tool.black]
line-length = 88
target-version = ['py39']
include = '\.pyi?
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
known_first_party = ["src"]

[tool.pylint.messages_control]
disable = ["C0114", "C0115", "C0116", "R0903"]

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "--cov=src --cov-report=html --cov-report=term-missing"
```

---

## üöÄ **Development Workflow & Best Practices**

### **Getting Started with VSCode & Claude Code**

1. **Project Initialization**
```bash
# Clone or create project directory
git clone <your-repo> grant-research-automation
cd grant-research-automation

# Create virtual environment
python -m venv grant-research-env
source grant-research-env/bin/activate  # Windows: grant-research-env\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Set up pre-commit hooks
pre-commit install

# Initialize database
python -m src.core.database init

# Copy environment template
cp .env.example .env
# Edit .env with your API keys and settings
```

2. **Daily Development Workflow**
```bash
# Start development session
source grant-research-env/bin/activate
code .  # Opens VSCode

# Run tests before making changes
pytest

# Start development services
python main.py --mode=dev  # Starts API server
streamlit run src/dashboard/app.py  # Starts dashboard (separate terminal)

# Use Claude Code for development
# Ctrl+Shift+P -> "Claude Code: Ask Claude" for AI assistance
```

3. **Code Quality & Standards**
```bash
# Format code (runs automatically on save in VSCode)
black src/ tests/
isort src/ tests/

# Run linting
pylint src/

# Type checking
mypy src/

# Run all quality checks
./scripts/quality_check.sh
```

### **Key Improvements Over Previous Version**

#### **Architecture Improvements**
- **Eliminated Docker Complexity**: Native Python development environment
- **Modern Configuration**: Pydantic settings with environment variable support
- **Type Safety**: Full type hints with mypy checking
- **Async Support**: Asyncio for better performance with I/O operations
- **Plugin Architecture**: Easy to add new processors without core changes

#### **Code Quality Improvements**
- **Better Error Handling**: Comprehensive exception handling with specific error types
- **Logging**: Structured logging with different levels and file rotation
- **Testing**: Comprehensive test suite with fixtures and mocking
- **Documentation**: Inline code comments and comprehensive docstrings

#### **User Experience Improvements**
- **Real-time Updates**: Live workflow progress monitoring
- **Better UI**: Modern Streamlit dashboard with interactive components
- **Export Options**: Multiple export formats (CSV, Excel, PDF reports)
- **Configuration Management**: Easy-to-use configuration interface

#### **Performance Improvements**
- **Caching**: Intelligent caching of API responses and processed data
- **Concurrency**: Parallel processing where appropriate
- **Database**: SQLite with proper indexing for fast queries
- **Memory Management**: Efficient data handling for large datasets

### **Migration Path from Existing Scripts**

Your existing scripts can be migrated as follows:
- `Step_00_lookup_from_ein.py` ‚Üí `src/processors/lookup/ein_lookup.py`
- `Step_01_filter_irsbmf.py` ‚Üí `src/processors/filtering/bmf_filter.py`
- `Step_02_download_990s_propublica.py` ‚Üí `src/processors/data_collection/propublica_fetch.py`
- `Step_03_score_990s.py` ‚Üí `src/processors/analysis/financial_scorer.py`
- `Step_04_*_download.py` ‚Üí `src/processors/data_collection/xml_downloader.py` & `pdf_downloader.py`
- `Step_05_ocr_and_score_pdfs.py` ‚Üí `src/processors/analysis/pdf_ocr.py`

### **Next Steps for Implementation**

1. **Phase 1** (Week 1): Set up project structure and migrate core processors
2. **Phase 2** (Week 2): Implement workflow engine and basic dashboard
3. **Phase 3** (Week 3): Add enhanced analysis processors and reporting
4. **Phase 4** (Week 4): Testing, documentation, and performance optimization
5. **Phase 5** (Week 5): Advanced features and deployment preparation

This design provides a solid foundation for rebuilding your grant research automation system with modern development practices, better maintainability, and enhanced functionality.